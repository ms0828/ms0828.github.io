---
title: "Projection Transform 개념과 Parallel Projection"
excerpt: ""

categories:
  - Computer Graphics
tags:
  - [tag1, tag2]

permalink: /categories/computer_graphics/projection_transform/

toc: true
toc_sticky: true

date: 2024-11-06
last_modified_at: 2024-11-06
---
# 🦥 Projection Transform
이전 글에서 정리한대로 View Transform을 수행하면 카메라 좌표계 기준으로 객체들의 위치와 방향이 변환 된다고 했다. <br>
이 후, 우리는 카메라 시점을 기준으로 카메라가 볼 수 있는 3차원 공간의 범위인 View Volume을 정의할 수 있다. 그리고 정의한 View Volume안의 점들을 대상으로 Projection Transform을 수행함으로써, Clipping과 Nomarlize, 객체의 원근감을 처리한다. 이 과정을 모두 거치면 Normalized Device Coordinate(NDC)를 얻을 수 있고, 비로소 화면 픽셀 좌표로 매핑할 수 있는 Window Coordinates로 변환할 준비를 마치게 된다.<br>

따라서 Projection Transform의 의미는 다음과 같다.
> 3D 공간에서 정의된 물체의 좌표를 2D 화면에 적절하게 투영하기 위해 필요한 변환 행렬을 계산하고, 이 변환 행렬로 부터 카메라 좌표계를 **Normalized Device Coordinates(NDC)**로 변환해서 화면에 그릴 준비를 하는 역할을 하는 것이다.

<br><br>



## Parallel Projections
![projection1](/assets\images\posts_img\graphics\projection1.png)

**Parallel Projection**은 3D 객체를 2D 평면에 투영할 때, **평행한 선들을 따라 투영하는 방식**이다. 이 방식은 투영하는 선이 모두 평행하게 유지되며, 일반적으로 물체의 크기를 원근감 없이 동일하게 표현한다.<br>


<br>

### Orthographic Projection
![projection2](/assets\images\posts_img\graphics\projection2.png)

**Orthographic Projection**은 Parallel Projection의 한 종류로, **투영선이 투영 평면에 수직으로 만나는 특성**을 가지고 있다. Orthographic Projection은 물체가 카메라로부터 멀어져도 크기가 변하지 않기 때문에, Parallel과 마찬가지로 원근감이 없는 평면적인 이미지를 얻을 수 있다.<br>

- 객체의 실제 크기를 왜곡 없이 표현하기 때문에, 정확한 길이와 비율을 유지해야 하는 도면 작업에 적합

<br><br>



## 직접 OpenGL로 Orthographic Viewing 구해보기
카메라가 원점에서 -z 방향 바라보는 Orthographic Viewing을 구현해보려고 한다. 옛날 OpenGL에서 사용하던, Orthographic Projection Transform을 수행하는 변환 행렬을 만드는 함수인 glOrtho()를 구현하는 것이 목적이며, 단계는 다음과 같다.

> 단순한 투영이므로 Clip Coordinate를 따로 구하지 않고, 한 번에 nomarlized계산할 예정

<br>

1. glOrtho의 인자로 (xmin, xmax, ymin, ymax, near, far)를 넘겨준다.
   - 이 값들은 View Volume을 정의하게 된다. (Orthographic Projection의 경우 View Volume은 직육면체 형태로 정의된다.)
2. 정의한 View Volume을 원점 기준으로 이동시키고(단 z축은 시작점이 0이 되도록 한다. 그래야 다음 코드에서 보일 것임), Nomarlized하여 Canonical view volume을 구한다.
   - Normalized view volume 밖의 점은 OpenGL에서 자동으로 Rasterizer하지 않으므로, Clipping 과정도 생략

<br>

수식으로 보면 다음과 같다.

![projection4](/assets\images\posts_img\graphics\projection4.png)

<br><br>

### 코드

```
#include <vgl.h>
#include <InitShader.h>
#include <mat.h>
#include "MyCube.h"
#include "MyPyramid.h"

MyCube cube;
MyPyramid pyramid;

GLuint program;
GLuint uMat;

mat4 g_Mat = mat4(1.0);

float g_Time = 0;
float g_aspect = 1.0f;			// aspect ratio(종횡비)
								// width/height > 1
float g_winWidth = 500;
float g_winHeight = 500;


void myInit()
{
	cube.Init();
	pyramid.Init();

	program = InitShader("vshader.glsl", "fshader.glsl");
	glUseProgram(program);
}

mat4 myLookAt(vec3 eye, vec3 focus, vec3 up)
{
	vec3 n = focus - eye;
	n = normalize(n);
	vec3 u = dot(n, up)*n;
	vec3 v = up - u;
	v = normalize(v);
	vec3 w = cross(v, -n);
	w = normalize(w);

	mat4 Rw(1.0f);
	Rw[0][0] = w.x;	Rw[0][1] = v.x;	Rw[0][2] = -n.x;
	Rw[1][0] = w.y;	Rw[1][1] = v.y;	Rw[1][2] = -n.y;
	Rw[2][0] = w.z;	Rw[2][1] = v.z;	Rw[2][2] = -n.z;

	mat4 Rc(1.0f);
	Rc[0][0] = w.x;	Rc[0][1] = w.y;	Rc[0][2] = w.z;
	Rc[1][0] = v.x;	Rc[1][1] = v.y;	Rc[1][2] = v.z;
	Rc[2][0] =-n.x;	Rc[2][1] =-n.y;	Rc[2][2] =-n.z;

//	Rc = transpose(Rw);
	mat4 T = Translate(-eye.x, -eye.y, -eye.z);
	
	return Rc * T;
}


mat4 myOrtho(float left, float right, 
	         float bottom, float top,
	         float zNear, float zFar)
{
	float cx = (left + right) / 2;
	float cy = (bottom + top) / 2;
	float cz = -zNear;

	float sx =  2 / (right - left);
	float sy =  2 / (top - bottom);
	float sz = 1 / (zFar - zNear);

	mat4 T = Translate(-cx, -cy, -cz);
	mat4 S = Scale(sx, sy, sz);
	return S * T;
}

void myDisplay()
{
	glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);
	glEnable(GL_DEPTH_TEST);
	
	g_aspect = g_winWidth / (float)g_winHeight;
	glViewport(0, 0, g_winWidth, g_winHeight);

	GLuint uMat = glGetUniformLocation(program, "uMat");

	//quantize (양자화)
	//0~z : n등분해서 단계로 표현하는 것
	float ex = 2 * cos(2 * 3.141592 * g_Time / 2);
	float ez = 2 * sin(2 * 3.141592 * g_Time / 2);

	vec3 eye(ex, 2 * sin(g_Time) + 2, ez);
	vec3 focus(0, 0, 0);
	vec3 up(0, 1, 0);
	mat4 V = myLookAt(eye, focus, up);

	// aspect = width / height
	float xmax = 2;
	float ymax = xmax / g_aspect;
	mat4 P = myOrtho(-xmax, xmax, -ymax, ymax, 0, 10);

	mat4 M(1.0);
	glUniformMatrix4fv(uMat, 1, true, P*V*M);

	//pyramid.Draw(program);
	cube.Draw(program);
	glutSwapBuffers();
}

void myIdle()
{
	g_Time += 0.016f;
	Sleep(16);
	glutPostRedisplay();
}

void myReshape(int winW, int winH) {
	g_winWidth = winW;
	g_winHeight = winH;

}

int main(int argc, char ** argv)
{
	glutInit(&argc, argv);
	glutInitDisplayMode(GLUT_DOUBLE|GLUT_RGBA|GLUT_DEPTH);
	glutInitWindowSize(g_winWidth,g_winHeight);
	glutCreateWindow("Cube and Pyramid");

	glewExperimental = true;
	glewInit();

	myInit();
	glutDisplayFunc(myDisplay);
	glutIdleFunc(myIdle);
	glutReshapeFunc(myReshape);

	glutMainLoop();

	return 0;
}
```




---- 수업 시간 필기 (Temp)------

- z값의 가시거리는 1로 설정되어 있는 이유(왜 가시거리가 정해지는지) : z은 기본으로 float(많은 메모리, 느린 연산)이기 때문에, zbuffer는 거리 값을 비트 단위로 정수화해서 거리를 기억함. 그래서 최대 값을 정해주어야 거리를 정확히 계산할 수 있음.
- depth buffer의 해상도 때문에 시야 거리의 제한을 줘야함

- glutInitWindowSize(500,500) - viewport가 500,500이기 때문에 aspect를 최신화하여도 500,500만 그려짐
- 따라서 glViewport() 함수로 뷰 포트를 다시 설정
